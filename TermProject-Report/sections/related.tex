The problem of finding connected components of a graph has been long studied in various distributed environments including the classical Parallel RAM (PRAM) model, the Block Synchronous Parallel Map Reduce. Since this project was mainly focused on Map Reduce implementations of the connected components algorithm, we are going to further elaborate only on Map Reduce implementations.

The work in \cite{rastogi} introduces an $O(logn)$ rounds Map Reduce algorithm, where n is the number of total nodes in the graph. This paper also describes an algorithm called Hash-to-Min which has proven to be even faster in practice. This algorithm is also the first that we implemented in this project. The major downside of this algorithm, however, is that it increases the intermediate data size in each Map Reduce round by up to a factor of 2. This work is the one most closely related to ours, since we are using the algorithm described above as our base implementation for our Map-Reduce approach. The writers also proposed another algorithm namely Hash-to-All, which is less efficient, since it builds the cluster of a connected component in each node instead of just building it on the leader node (usually the leader is the node with the smallest label).

In \cite{kiveris}, the authors propose some novel algorithms to calculate connected components in a graph more efficiently. Their algorithm \textit{Two-Phase} iteratively transforms the input graph over multiple Map-Reduce rounds. This algorithm is local, with every node in the graph making decisions solely depending on its immediate neighborhood. The drawback is that the execution time is dependent on the degree of the node, but it allows for a straightforward implementation in a distributed environment. Compared to Hash-to-Min, the main advantage is that involves less communication overhead compared to the algorithms presented in \cite{rastogi}. A further improvement is proposed by utilizing a Distributed Hash Table (\ie DHT) that reduces the algorithm's running time. 

The work in \cite{lim2015} follows another approach and makes use of Graph databases to perform efficient graph processing at a large scale. Graph databases provide a more efficient and easy to manipulate way of storing and querying graph data. In particular, the authors investigate popular graph databases (Neo4j, Titan) and propose algorithms to compute connected components using Map-Reduce on top of these databases. The rational behind this is to take advantage of the representation of graphs in these databases, which makes it more efficient to query the graphs in general. They also explore Pregel \cite{pregel} as an alternative for graph analysis that alleviates many of the Map-Reduce paradigm's limitations.