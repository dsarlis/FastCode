\subsection{Datasets}

All the input files we used consist of edges making it straightforward to parse them as showed in \ref{fig:graphfileformat}.

\begin{verbbox}
node_from_1 node_to_1
node_from_2 node_to_2
...
node_from_n node_to_n
\end{verbbox}

\begin{figure}[ht]
  \centering
  \theverbbox
  \caption{Graph file format}
  \label{fig:graphfileformat}
\end{figure}

We used different graph files taken from \cite{datasets} to measure both the Sequential and Map-Redude algorithm performance. The following table describes different metrics of each one:

\begin{table}[h!]
\footnotesize
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
{\bf Name} & {\bf Nodes}& {\bf Edges} & {\bf Size}\\
\hline
\hline
simple\_graph   & 10  & 14  & 55 bytes  \\
\hline
medium\_graph   & -  & 9625  & 96.2 Kb  \\
\hline
ego-Facebook   & 4039  & 88234  & 854.4 Kb  \\
\hline
ego-Gplus   & 107614  & 13673453  & 1.2GB  \\
\hline
big\_graph   & -  & -  & 2.4GB  \\
\hline
\end{tabular}
\caption{Graphs}
\label{tb:graphfiles}
\end{center}
\end{table}

\subsection{Sequential}
We used an implementation of Tarjan's Algorithm that has $O(|V| + |E|)$ worst case performance. It uses a Depth-First-Approach (DFS) as described in Section \ref{sec:algo}. It begins at an arbitrary node and  visits every node of the graph exactly once. As it is going through the graph it will be generating the various connected components.

\begin{table}[!h]
\footnotesize
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
{\bf Graph} & {\bf Time (milliseconds)}& {\bf components \#} \\
\hline
\hline
simple\_graph   & 0  & 3  \\
\hline
medium\_graph   & 4  & 2   \\
\hline
ego-Facebook   & 11  & 1325  \\
\hline
ego-Gplus   & 812 & 37249 \\
\hline
big\_graph   & -  & -  \\
\hline
\end{tabular}
\caption{Sequential times}
\label{tb:sequentialtimes}
\end{center}
\end{table}

The results here are as expected. The algorithm performs really well when using small files and the total execution time is really small. However, we can see that as the files grow bigger and bigger the parsing time starts becoming the dominating factor that takes up more than half of the total execution time.

\subsection{Map-Reduce}

\begin{table}[h!]
\footnotesize
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
{\bf Graph} & {\bf Phase 1 (sec)} & {\bf Phase 2 (sec)}\\
\hline
\hline
simple\_graph   & 10  & 45 \\
\hline
medium\_graph   & 12 & 60 \\
\hline
ego-Facebook   & 30 & 150 \\
\hline
ego-Gplus   & 60  & 220 \\
\hline
big\_graph   & 240 & 1740 \\
\hline
\end{tabular}
\caption{Map-Reduce times}
\label{tb:MapReducetimes}
\end{center}
\end{table}
